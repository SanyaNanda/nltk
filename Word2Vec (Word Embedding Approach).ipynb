{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec is a word embedding approach \n",
    "#### It first converts the words to vectors and then places the similar words or closely used words in a text together, by placing them close as vectors by assigning affinity to the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a paragraph on neural networks\n",
    "para = \"\"\"A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data \n",
    "through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, \n",
    "either organic or artificial in nature. Neural networks can adapt to changing input; so the network generates the best possible \n",
    "result without needing to redesign the output criteria. The concept of neural networks, which has its roots in artificial \n",
    "intelligence, is swiftly gaining popularity in the development of trading systems.Neural networks, in the world of finance, \n",
    "assist in the development of such process as time-series forecasting, algorithmic trading, securities classification, credit \n",
    "risk modeling and constructing proprietary indicators and price derivatives.\n",
    "A neural network works similarly to the human brain’s neural network. A “neuron” in a neural network is a mathematical function \n",
    "that collects and classifies information according to a specific architecture. The network bears a strong resemblance to \n",
    "statistical methods such as curve fitting and regression analysis.\n",
    "A neural network contains layers of interconnected nodes. Each node is a perceptron and is similar to a multiple linear \n",
    "regression. The perceptron feeds the signal produced by a multiple linear regression into an activation function that may be \n",
    "nonlinear.In a multi-layered perceptron (MLP), perceptrons are arranged in interconnected layers. The input layer collects \n",
    "input patterns. The output layer has classifications or output signals to which input patterns may map. For instance, the \n",
    "patterns may comprise a list of quantities for technical indicators about a security; potential outputs could be “buy,” “hold” \n",
    "or “sell.”\n",
    "Hidden layers fine-tune the input weightings until the neural network’s margin of error is minimal. It is hypothesized that \n",
    "hidden layers extrapolate salient features in the input data that have predictive power regarding the outputs. This describes \n",
    "feature extraction, which accomplishes a utility similar to statistical techniques such as principal component analysis.Neural \n",
    "networks are broadly used, with applications for financial operations, enterprise planning, trading, business analytics and \n",
    "product maintenance. Neural networks have also gained widespread adoption in business applications such as forecasting and \n",
    "marketing research solutions, fraud detection and risk assessment.\n",
    "A neural network evaluates price data and unearths opportunities for making trade decisions based on the data analysis. The \n",
    "networks can distinguish subtle nonlinear interdependencies and patterns other methods of technical analysis cannot. According \n",
    "to research, the accuracy of neural networks in making price predictions for stocks differs. Some models predict the correct \n",
    "stock prices 50 to 60 percent of the time while others are accurate in 70 percent of all instances. Some have posited that a 10 \n",
    "percent improvement in efficiency is all an investor can ask for from a neural network.\n",
    "There will always be data sets and task classes that a better analyzed by using previously developed algorithms. It is not so \n",
    "much the algorithm that matters; it is the well-prepared input data on the targeted indicator that ultimately determines the \n",
    "level of success of a neural network.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',para) \n",
    "text = re.sub(r'\\s+',' ',text) \n",
    "text = text.lower() \n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['neural', 'network', 'series', 'algorithms', 'endeavors', 'recognize', 'underlying', 'relationships', 'set', 'data', 'process', 'mimics', 'way', 'human', 'brain', 'operates', '.'], ['sense', ',', 'neural', 'networks', 'refer', 'systems', 'neurons', ',', 'either', 'organic', 'artificial', 'nature', '.'], ['neural', 'networks', 'adapt', 'changing', 'input', ';', 'network', 'generates', 'best', 'possible', 'result', 'without', 'needing', 'redesign', 'output', 'criteria', '.'], ['concept', 'neural', 'networks', ',', 'roots', 'artificial', 'intelligence', ',', 'swiftly', 'gaining', 'popularity', 'development', 'trading', 'systems.neural', 'networks', ',', 'world', 'finance', ',', 'assist', 'development', 'process', 'time-series', 'forecasting', ',', 'algorithmic', 'trading', ',', 'securities', 'classification', ',', 'credit', 'risk', 'modeling', 'constructing', 'proprietary', 'indicators', 'price', 'derivatives', '.'], ['neural', 'network', 'works', 'similarly', 'human', 'brain', '’', 'neural', 'network', '.'], ['“', 'neuron', '”', 'neural', 'network', 'mathematical', 'function', 'collects', 'classifies', 'information', 'according', 'specific', 'architecture', '.'], ['network', 'bears', 'strong', 'resemblance', 'statistical', 'methods', 'curve', 'fitting', 'regression', 'analysis', '.'], ['neural', 'network', 'contains', 'layers', 'interconnected', 'nodes', '.'], ['node', 'perceptron', 'similar', 'multiple', 'linear', 'regression', '.'], ['perceptron', 'feeds', 'signal', 'produced', 'multiple', 'linear', 'regression', 'activation', 'function', 'may', 'nonlinear.in', 'multi-layered', 'perceptron', '(', 'mlp', ')', ',', 'perceptrons', 'arranged', 'interconnected', 'layers', '.'], ['input', 'layer', 'collects', 'input', 'patterns', '.'], ['output', 'layer', 'classifications', 'output', 'signals', 'input', 'patterns', 'may', 'map', '.'], ['instance', ',', 'patterns', 'may', 'comprise', 'list', 'quantities', 'technical', 'indicators', 'security', ';', 'potential', 'outputs', 'could', '“', 'buy', ',', '”', '“', 'hold', '”', '“', 'sell.', '”', 'hidden', 'layers', 'fine-tune', 'input', 'weightings', 'neural', 'network', '’', 'margin', 'error', 'minimal', '.'], ['hypothesized', 'hidden', 'layers', 'extrapolate', 'salient', 'features', 'input', 'data', 'predictive', 'power', 'regarding', 'outputs', '.'], ['describes', 'feature', 'extraction', ',', 'accomplishes', 'utility', 'similar', 'statistical', 'techniques', 'principal', 'component', 'analysis.neural', 'networks', 'broadly', 'used', ',', 'applications', 'financial', 'operations', ',', 'enterprise', 'planning', ',', 'trading', ',', 'business', 'analytics', 'product', 'maintenance', '.'], ['neural', 'networks', 'also', 'gained', 'widespread', 'adoption', 'business', 'applications', 'forecasting', 'marketing', 'research', 'solutions', ',', 'fraud', 'detection', 'risk', 'assessment', '.'], ['neural', 'network', 'evaluates', 'price', 'data', 'unearths', 'opportunities', 'making', 'trade', 'decisions', 'based', 'data', 'analysis', '.'], ['networks', 'distinguish', 'subtle', 'nonlinear', 'interdependencies', 'patterns', 'methods', 'technical', 'analysis', '.'], ['according', 'research', ',', 'accuracy', 'neural', 'networks', 'making', 'price', 'predictions', 'stocks', 'differs', '.'], ['models', 'predict', 'correct', 'stock', 'prices', 'percent', 'time', 'others', 'accurate', 'percent', 'instances', '.'], ['posited', 'percent', 'improvement', 'efficiency', 'investor', 'ask', 'neural', 'network', '.'], ['always', 'data', 'sets', 'task', 'classes', 'better', 'analyzed', 'using', 'previously', 'developed', 'algorithms', '.'], ['much', 'algorithm', 'matters', ';', 'well-prepared', 'input', 'data', 'targeted', 'indicator', 'ultimately', 'determines', 'level', 'success', 'neural', 'network', '.']]\n"
     ]
    }
   ],
   "source": [
    "# words are tokenised and stopwords removed\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]\n",
    "print(sentences) # List of meaningful words in the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=2) \n",
    "# min count = 2 means that only those tokens will be considered which have appeared 2 or more times in the \n",
    "# paragraph over all the sentences\n",
    "words = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neural': <gensim.models.keyedvectors.Vocab at 0x15079635ef0>,\n",
       " 'network': <gensim.models.keyedvectors.Vocab at 0x15079635f60>,\n",
       " 'algorithms': <gensim.models.keyedvectors.Vocab at 0x15079635f98>,\n",
       " 'data': <gensim.models.keyedvectors.Vocab at 0x15079635a20>,\n",
       " 'process': <gensim.models.keyedvectors.Vocab at 0x15079635978>,\n",
       " 'human': <gensim.models.keyedvectors.Vocab at 0x15079635940>,\n",
       " 'brain': <gensim.models.keyedvectors.Vocab at 0x150796359b0>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x15078165e80>,\n",
       " ',': <gensim.models.keyedvectors.Vocab at 0x150775cecc0>,\n",
       " 'networks': <gensim.models.keyedvectors.Vocab at 0x1507816db38>,\n",
       " 'artificial': <gensim.models.keyedvectors.Vocab at 0x15077a95e48>,\n",
       " 'input': <gensim.models.keyedvectors.Vocab at 0x15077a95d68>,\n",
       " ';': <gensim.models.keyedvectors.Vocab at 0x1506ea453c8>,\n",
       " 'output': <gensim.models.keyedvectors.Vocab at 0x1506c44c9e8>,\n",
       " 'development': <gensim.models.keyedvectors.Vocab at 0x1506c44cf98>,\n",
       " 'trading': <gensim.models.keyedvectors.Vocab at 0x150782dfeb8>,\n",
       " 'forecasting': <gensim.models.keyedvectors.Vocab at 0x150781cb470>,\n",
       " 'risk': <gensim.models.keyedvectors.Vocab at 0x150781cb4a8>,\n",
       " 'indicators': <gensim.models.keyedvectors.Vocab at 0x150783f1da0>,\n",
       " 'price': <gensim.models.keyedvectors.Vocab at 0x150783f1cf8>,\n",
       " '’': <gensim.models.keyedvectors.Vocab at 0x150783f1be0>,\n",
       " '“': <gensim.models.keyedvectors.Vocab at 0x150783f1b38>,\n",
       " '”': <gensim.models.keyedvectors.Vocab at 0x150783f1c50>,\n",
       " 'function': <gensim.models.keyedvectors.Vocab at 0x150783f1cc0>,\n",
       " 'collects': <gensim.models.keyedvectors.Vocab at 0x150783f1828>,\n",
       " 'according': <gensim.models.keyedvectors.Vocab at 0x150783f1668>,\n",
       " 'statistical': <gensim.models.keyedvectors.Vocab at 0x150783f1780>,\n",
       " 'methods': <gensim.models.keyedvectors.Vocab at 0x150783f17f0>,\n",
       " 'regression': <gensim.models.keyedvectors.Vocab at 0x150783f16a0>,\n",
       " 'analysis': <gensim.models.keyedvectors.Vocab at 0x150783f1748>,\n",
       " 'layers': <gensim.models.keyedvectors.Vocab at 0x15079635cc0>,\n",
       " 'interconnected': <gensim.models.keyedvectors.Vocab at 0x15079635ac8>,\n",
       " 'perceptron': <gensim.models.keyedvectors.Vocab at 0x15079635d68>,\n",
       " 'similar': <gensim.models.keyedvectors.Vocab at 0x150796359e8>,\n",
       " 'multiple': <gensim.models.keyedvectors.Vocab at 0x150796356a0>,\n",
       " 'linear': <gensim.models.keyedvectors.Vocab at 0x150796357b8>,\n",
       " 'may': <gensim.models.keyedvectors.Vocab at 0x15079635748>,\n",
       " 'layer': <gensim.models.keyedvectors.Vocab at 0x150796355f8>,\n",
       " 'patterns': <gensim.models.keyedvectors.Vocab at 0x15079635630>,\n",
       " 'technical': <gensim.models.keyedvectors.Vocab at 0x150796357f0>,\n",
       " 'outputs': <gensim.models.keyedvectors.Vocab at 0x15079635710>,\n",
       " 'hidden': <gensim.models.keyedvectors.Vocab at 0x15079635198>,\n",
       " 'applications': <gensim.models.keyedvectors.Vocab at 0x15079635160>,\n",
       " 'business': <gensim.models.keyedvectors.Vocab at 0x15079635080>,\n",
       " 'research': <gensim.models.keyedvectors.Vocab at 0x150796352b0>,\n",
       " 'making': <gensim.models.keyedvectors.Vocab at 0x15079635358>,\n",
       " 'percent': <gensim.models.keyedvectors.Vocab at 0x150796350b8>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7882499e-03 -7.3534460e-04  3.5770691e-03 -3.5137567e-03\n",
      " -1.3872167e-03 -4.8282347e-03 -2.2223189e-03  2.8980188e-03\n",
      "  2.3327591e-03 -4.1577322e-03  1.7765195e-03  3.5341179e-03\n",
      " -2.6832540e-03  1.7329424e-03  4.0831664e-03 -4.7500078e-03\n",
      "  3.0543541e-03 -3.2694545e-03  2.6768423e-03  1.7643366e-03\n",
      "  2.9024247e-03 -4.6829074e-03 -1.9399243e-03 -5.2071345e-04\n",
      "  3.7325355e-03 -3.4103862e-03 -1.0379353e-03 -2.3358960e-03\n",
      " -2.0473127e-03  4.7081904e-03 -3.7244470e-03  2.9085134e-03\n",
      " -1.8144966e-03 -3.9202212e-03 -3.8085724e-03  2.4605305e-03\n",
      " -4.4240062e-03 -4.6432149e-03  1.5382556e-04  3.0929346e-03\n",
      "  4.2525982e-03 -2.0447746e-03 -3.8713627e-03  4.8777862e-03\n",
      "  4.4917697e-03  1.3928565e-03  1.2972564e-03 -5.3491979e-04\n",
      "  3.6973676e-03  1.1728632e-03  3.9730929e-03  1.8387869e-03\n",
      " -7.9959910e-04 -8.3132116e-05 -2.7351961e-03 -1.2522034e-04\n",
      " -1.4878893e-03  3.6511519e-03  2.5038652e-03 -3.7544046e-03\n",
      "  4.6441276e-03  3.1028336e-03  1.3241119e-03  1.0910855e-03\n",
      " -2.7851027e-03 -1.1458225e-05 -1.9365972e-03 -4.8408606e-03\n",
      " -2.0230165e-05 -1.1403782e-03  3.4728146e-04  3.0771936e-03\n",
      " -1.9195545e-04  4.2322101e-03  4.2188093e-03 -1.8651538e-04\n",
      " -1.4397819e-03 -3.3576926e-03 -2.7568410e-03  4.1797995e-03\n",
      " -5.6545692e-04  2.0161797e-03 -4.2995806e-03 -1.6854816e-03\n",
      "  8.5732871e-04 -3.6543284e-03  1.6712849e-05  2.2630887e-03\n",
      " -4.7381502e-03 -9.5963955e-04 -5.5758355e-05  4.3637455e-03\n",
      " -3.6709253e-03  3.3860595e-03 -1.9566598e-03  4.4986405e-03\n",
      "  1.6668134e-03 -3.8684073e-03 -3.0881662e-03 -1.5549903e-04]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv['analysis']\n",
    "print(vector)\n",
    "print(len(vector)) # these are points that the word 'analysis' marks over 100 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 0.2724544107913971),\n",
       " ('statistical', 0.24404123425483704),\n",
       " ('regression', 0.17220473289489746),\n",
       " ('collects', 0.14969736337661743),\n",
       " ('technical', 0.12971970438957214),\n",
       " ('neural', 0.12779946625232697),\n",
       " ('making', 0.12751170992851257),\n",
       " ('”', 0.11790597438812256),\n",
       " ('“', 0.11625520139932632),\n",
       " ('according', 0.11557957530021667)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generates a list of words closely used with word mentioned\n",
    "similar = model.wv.most_similar('artificial')\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layers', 0.16600537300109863),\n",
       " ('hidden', 0.13354891538619995),\n",
       " ('multiple', 0.13139352202415466),\n",
       " ('artificial', 0.12779945135116577),\n",
       " ('networks', 0.12183421850204468),\n",
       " ('perceptron', 0.11365452408790588),\n",
       " ('outputs', 0.09578442573547363),\n",
       " ('data', 0.0943332314491272),\n",
       " ('development', 0.08591002225875854),\n",
       " ('layer', 0.0827164426445961)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = model.wv.most_similar('neural')\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trading', 0.2603369951248169),\n",
       " ('linear', 0.22607269883155823),\n",
       " ('methods', 0.19584564864635468),\n",
       " ('patterns', 0.17461207509040833),\n",
       " ('”', 0.15355277061462402),\n",
       " ('making', 0.13648977875709534),\n",
       " ('research', 0.11855696886777878),\n",
       " ('regression', 0.11451949179172516),\n",
       " ('algorithms', 0.10579060763120651),\n",
       " ('perceptron', 0.1013592928647995)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = model.wv.most_similar('price')\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'neural' and 'networks' - CBOW :  0.12134572\n",
      "Cosine similarity between 'neural' and 'statistical' - CBOW :  -0.064506575\n",
      "Cosine similarity between 'neural' and 'networks' - Skip Gram :  0.3636789\n",
      "Cosine similarity between 'neural' and 'statistical' - Skip Gram :  0.07178426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\sanya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"\n",
      "c:\\users\\sanya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\sanya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Create CBOW model \n",
    "model1 = Word2Vec(sentences, min_count = 1,  size = 200, window = 20) \n",
    "print(\"Cosine similarity between 'neural' \" + \"and 'networks' - CBOW : \", model1.similarity('neural', 'networks')) \n",
    "      \n",
    "print(\"Cosine similarity between 'neural' \" +\"and 'statistical' - CBOW : \", model1.similarity('neural', 'statistical')) \n",
    "  \n",
    "# Create Skip Gram model \n",
    "model2 = Word2Vec(sentences, min_count = 1, size = 200, window = 20, sg = 1)  \n",
    "print(\"Cosine similarity between 'neural' \" + \"and 'networks' - Skip Gram : \", model2.similarity('neural', 'networks')) \n",
    "      \n",
    "print(\"Cosine similarity between 'neural' \" +\"and 'statistical' - Skip Gram : \", model2.similarity('neural', 'statistical')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
