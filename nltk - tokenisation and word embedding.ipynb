{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "##### Given a character sequence and a defined document unit, tokenization is the task of slicing it up into pieces, called tokens ,  at the same time throwing away certain characters, such as punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # Natural Language ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A general paragraph on Inflation\n",
    "para=\"\"\"Inflation is a quantitative measure of the rate at which the average price level of a basket of selected goods and services in an economy increases over some period of time. \n",
    "It is the rise in the general level of prices where a unit of currency effectively buys less than it did in prior periods. \n",
    "Often expressed as a percentage, inflation thus indicates a decrease in the purchasing power of a nation’s currency.\n",
    "As prices rise, a single unit of currency loses value as it buys fewer goods and services. \n",
    "This loss of purchasing power impacts the general cost of living for the common public which ultimately leads to a deceleration in economic growth. \n",
    "The consensus view among economists is that sustained inflation occurs when a nation's money supply growth outpaces economic growth.\n",
    "To combat this, a country's appropriate monetary authority, like the central bank, then takes the necessary measures to keep inflation within permissible limits and keep the economy running smoothly.\n",
    "Inflation is measured in a variety of ways depending upon the types of goods and services considered and is the opposite of deflation which indicates a general decline occurring in prices for goods and services when the inflation rate falls below 0%. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inflation is a quantitative measure of the rate at which the average price level of a basket of selected goods and services in an economy increases over some period of time.', 'It is the rise in the general level of prices where a unit of currency effectively buys less than it did in prior periods.', 'Often expressed as a percentage, inflation thus indicates a decrease in the purchasing power of a nation’s currency.', 'As prices rise, a single unit of currency loses value as it buys fewer goods and services.', 'This loss of purchasing power impacts the general cost of living for the common public which ultimately leads to a deceleration in economic growth.', \"The consensus view among economists is that sustained inflation occurs when a nation's money supply growth outpaces economic growth.\", \"To combat this, a country's appropriate monetary authority, like the central bank, then takes the necessary measures to keep inflation within permissible limits and keep the economy running smoothly.\", 'Inflation is measured in a variety of ways depending upon the types of goods and services considered and is the opposite of deflation which indicates a general decline occurring in prices for goods and services when the inflation rate falls below 0%.']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(para) #gives a list of sentences in the paragraph\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inflation', 'is', 'a', 'quantitative', 'measure', 'of', 'the', 'rate', 'at', 'which', 'the', 'average', 'price', 'level', 'of', 'a', 'basket', 'of', 'selected', 'goods', 'and', 'services', 'in', 'an', 'economy', 'increases', 'over', 'some', 'period', 'of', 'time', '.', 'It', 'is', 'the', 'rise', 'in', 'the', 'general', 'level', 'of', 'prices', 'where', 'a', 'unit', 'of', 'currency', 'effectively', 'buys', 'less', 'than', 'it', 'did', 'in', 'prior', 'periods', '.', 'Often', 'expressed', 'as', 'a', 'percentage', ',', 'inflation', 'thus', 'indicates', 'a', 'decrease', 'in', 'the', 'purchasing', 'power', 'of', 'a', 'nation', '’', 's', 'currency', '.', 'As', 'prices', 'rise', ',', 'a', 'single', 'unit', 'of', 'currency', 'loses', 'value', 'as', 'it', 'buys', 'fewer', 'goods', 'and', 'services', '.', 'This', 'loss', 'of', 'purchasing', 'power', 'impacts', 'the', 'general', 'cost', 'of', 'living', 'for', 'the', 'common', 'public', 'which', 'ultimately', 'leads', 'to', 'a', 'deceleration', 'in', 'economic', 'growth', '.', 'The', 'consensus', 'view', 'among', 'economists', 'is', 'that', 'sustained', 'inflation', 'occurs', 'when', 'a', 'nation', \"'s\", 'money', 'supply', 'growth', 'outpaces', 'economic', 'growth', '.', 'To', 'combat', 'this', ',', 'a', 'country', \"'s\", 'appropriate', 'monetary', 'authority', ',', 'like', 'the', 'central', 'bank', ',', 'then', 'takes', 'the', 'necessary', 'measures', 'to', 'keep', 'inflation', 'within', 'permissible', 'limits', 'and', 'keep', 'the', 'economy', 'running', 'smoothly', '.', 'Inflation', 'is', 'measured', 'in', 'a', 'variety', 'of', 'ways', 'depending', 'upon', 'the', 'types', 'of', 'goods', 'and', 'services', 'considered', 'and', 'is', 'the', 'opposite', 'of', 'deflation', 'which', 'indicates', 'a', 'general', 'decline', 'occurring', 'in', 'prices', 'for', 'goods', 'and', 'services', 'when', 'the', 'inflation', 'rate', 'falls', 'below', '0', '%', '.']\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(para) #gives a list of all the words used in the paragraph.\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "###### Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes.\n",
    "###### The most common algorithm for stemming English, and one that has repeatedly been shown to be empirically very effective, is Porter's algorithm (Porter, 1980). Porter's algorithm consists of 5 phases of word reductions, applied sequentially. Within each phase there are various conventions to select rules, such as selecting the rule from each rule group that applies to the longest suffix. \n",
    "![img100](https://user-images.githubusercontent.com/51756349/85506235-980c6280-b60d-11ea-803b-bf7a16dbfbfd.png)\n",
    "\n",
    "###### Many of the later rules use a concept of the measure of a word, which loosely checks the number of syllables to see whether a word is long enough that it is reasonable to regard the matching portion of a rule as a suffix rather than as part of the stem of a word. For example, the rule:\n",
    "\n",
    "#### (m>1)    EMENT    \n",
    "###### would map replacement to replac, but not cement to c. The official site for the Porter Stemmer is:\n",
    "###### http://www.tartarus.org/~martin/PorterStemmer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "#stopwords are those which help in completing the sentences, but do not give meaning to the sentences as such\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer() #returns the stem of a word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i]=''.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflatquantitmeasurrateaveragpricelevelbasketselectgoodserviceconomiincreasperiodtime.',\n",
       " 'Itrisegenerlevelpriceunitcurrenceffectbuylesspriorperiod.',\n",
       " 'oftenexpresspercentag,inflatthuindicdecreaspurchaspowernation’currenc.',\n",
       " 'Aspricerise,singlunitcurrenclosevalubuyfewergoodservic.',\n",
       " 'thilosspurchaspowerimpactgenercostlivecommonpublicultimleaddecelereconomgrowth.',\n",
       " \"theconsensuviewamongeconomistsustaininflatoccurnation'smoneysuppligrowthoutpaceconomgrowth.\",\n",
       " \"Tocombat,countri'sapproprimonetariauthor,likecentralbank,takenecessarimeasurkeepinflatwithinpermisslimitkeepeconomirunsmoothli.\",\n",
       " 'inflatmeasurvarietiwaydependupontypegoodservicconsidoppositdeflatindicgenerdeclinoccurpricegoodservicinflatratefall0%.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences #we get all the sentences with it's words in their stemmed form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "###### Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i]=''.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflatquantitmeasurrateaveragpricelevelbasketselectgoodserviceconomiincreasperiodtime.',\n",
       " 'Itrisegenerlevelpriceunitcurrenceffectbuylesspriorperiod.',\n",
       " 'oftenexpresspercentag,inflatthuindicdecreaspurchaspowernation’currenc.',\n",
       " 'Aspricerise,singlunitcurrenclosevalubuyfewergoodservic.',\n",
       " 'thilosspurchaspowerimpactgenercostlivecommonpublicultimleaddecelereconomgrowth.',\n",
       " \"theconsensuviewamongeconomistsustaininflatoccurnation'smoneysuppligrowthoutpaceconomgrowth.\",\n",
       " \"Tocombat,countri'sapproprimonetariauthor,likecentralbank,takenecessarimeasurkeepinflatwithinpermisslimitkeepeconomirunsmoothli.\",\n",
       " 'inflatmeasurvarietiwaydependupontypegoodservicconsidoppositdeflatindicgenerdeclinoccurpricegoodservicinflatratefall0%.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding approaches\n",
    "#### 1) Bag of Words\n",
    "#### 2) TF-IDF\n",
    "#### 3) Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Bag of Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_MeSYCKGDOdwkJKVZKxJuvg](https://user-images.githubusercontent.com/51756349/85506126-64313d00-b60d-11ea-8d8e-b540e71262d6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #importing regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [] # lemmatising the words and removing the stopwords\n",
    "count = 0 # will give the total number of words present in the corpus after removing the stop words \n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    count += len(review) \n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflation quantitative measure rate average price level basket selected good service economy increase period time',\n",
       " 'rise general level price unit currency effectively buy le prior period',\n",
       " 'often expressed percentage inflation thus indicates decrease purchasing power nation currency',\n",
       " 'price rise single unit currency loses value buy fewer good service',\n",
       " 'loss purchasing power impact general cost living common public ultimately lead deceleration economic growth',\n",
       " 'consensus view among economist sustained inflation occurs nation money supply growth outpaces economic growth',\n",
       " 'combat country appropriate monetary authority like central bank take necessary measure keep inflation within permissible limit keep economy running smoothly',\n",
       " 'inflation measured variety way depending upon type good service considered opposite deflation indicates general decline occurring price good service inflation rate fall']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['among', 'appropriate', 'authority', 'average', 'bank', 'basket', 'buy', 'central', 'combat', 'common', 'consensus', 'considered', 'cost', 'country', 'currency', 'deceleration', 'decline', 'decrease', 'deflation', 'depending', 'economic', 'economist', 'economy', 'effectively', 'expressed', 'fall', 'fewer', 'general', 'good', 'growth', 'impact', 'increase', 'indicates', 'inflation', 'keep', 'le', 'lead', 'level', 'like', 'limit', 'living', 'loses', 'loss', 'measure', 'measured', 'monetary', 'money', 'nation', 'necessary', 'occurring', 'occurs', 'often', 'opposite', 'outpaces', 'percentage', 'period', 'permissible', 'power', 'price', 'prior', 'public', 'purchasing', 'quantitative', 'rate', 'rise', 'running', 'selected', 'service', 'single', 'smoothly', 'supply', 'sustained', 'take', 'thus', 'time', 'type', 'ultimately', 'unit', 'upon', 'value', 'variety', 'view', 'way', 'within']\n"
     ]
    }
   ],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "print(count) # Total words in the corpus\n",
    "print(len(cv.get_feature_names())) #All the frequently used words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
      "  0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      "  0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      "  1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 2 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      "  0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 2 0\n",
      "  0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 2 0 0 0 1 2 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 2 0 0 0 0\n",
      "  0 0 0 1 0 0 1 0 1 0 1 0]]\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "X = cv.fit_transform(corpus).toarray() \n",
    "# Learn the vocabulary dictionary and return document-term matrix.\n",
    "# This is equivalent to fit followed by transform, but more efficiently implemented.\n",
    "print(X)\n",
    "print(len(X[0])) \n",
    "# Each row contains 84 elements marking the presence of the feature_names in the given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF : Term Frequency Inverse Document Frequency\n",
    "#### TF = Number of occurences of a word in a document / Number of words in the document\n",
    "#### IDF = log( Number of Documents / Number of documents containing word )\n",
    "#### TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.29781205 0.         0.29781205\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.24958974 0.\n",
      "  0.         0.         0.         0.         0.21537547 0.\n",
      "  0.         0.29781205 0.         0.16715316 0.         0.\n",
      "  0.         0.24958974 0.         0.         0.         0.\n",
      "  0.         0.24958974 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24958974 0.         0.         0.18883682 0.\n",
      "  0.         0.         0.29781205 0.24958974 0.         0.\n",
      "  0.29781205 0.21537547 0.         0.         0.         0.\n",
      "  0.         0.         0.29781205 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.29704987 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25632967 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.35444178\n",
      "  0.         0.         0.         0.25632967 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.35444178\n",
      "  0.         0.29704987 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.29704987 0.         0.         0.22474462 0.35444178\n",
      "  0.         0.         0.         0.         0.29704987 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29704987\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.24592795 0.         0.         0.34005873\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34005873 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.28499575 0.19086498 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.28499575\n",
      "  0.         0.         0.         0.34005873 0.         0.\n",
      "  0.34005873 0.         0.         0.28499575 0.         0.\n",
      "  0.         0.28499575 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.34005873 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.29486758 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25444653 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.35183785 0.         0.25444653 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.35183785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22309352 0.\n",
      "  0.         0.         0.         0.         0.29486758 0.\n",
      "  0.         0.25444653 0.35183785 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29486758\n",
      "  0.         0.35183785 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.28475694 0.         0.\n",
      "  0.28475694 0.         0.         0.28475694 0.         0.\n",
      "  0.         0.         0.23864854 0.         0.         0.\n",
      "  0.         0.         0.         0.20593411 0.         0.23864854\n",
      "  0.28475694 0.         0.         0.         0.         0.\n",
      "  0.28475694 0.         0.         0.         0.28475694 0.\n",
      "  0.28475694 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23864854 0.         0.\n",
      "  0.28475694 0.23864854 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.28475694 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.27187092 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.27187092 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22784905 0.27187092 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.4556981\n",
      "  0.         0.         0.         0.15259316 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.27187092 0.22784905\n",
      "  0.         0.         0.27187092 0.         0.         0.27187092\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.27187092 0.27187092\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.27187092 0.         0.        ]\n",
      " [0.         0.21968858 0.21968858 0.         0.21968858 0.\n",
      "  0.         0.21968858 0.21968858 0.         0.         0.\n",
      "  0.         0.21968858 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18411618 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.12330475 0.43937717 0.\n",
      "  0.         0.         0.21968858 0.21968858 0.         0.\n",
      "  0.         0.18411618 0.         0.21968858 0.         0.\n",
      "  0.21968858 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.21968858 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21968858\n",
      "  0.         0.         0.         0.21968858 0.         0.\n",
      "  0.21968858 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21968858]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22488113\n",
      "  0.         0.         0.         0.         0.22488113 0.\n",
      "  0.22488113 0.22488113 0.         0.         0.         0.\n",
      "  0.         0.22488113 0.         0.16263237 0.32526474 0.\n",
      "  0.         0.         0.18846794 0.25243835 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22488113 0.         0.         0.\n",
      "  0.         0.22488113 0.         0.         0.22488113 0.\n",
      "  0.         0.         0.         0.         0.14259274 0.\n",
      "  0.         0.         0.         0.18846794 0.         0.\n",
      "  0.         0.32526474 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22488113 0.         0.\n",
      "  0.22488113 0.         0.22488113 0.         0.22488113 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec is a two-layer neural net that processes text by “vectorizing” words. Its input is a text corpus and its output is a set of vectors: feature vectors that represent words in that corpus. While Word2vec is not a deep neural network, it turns text into a numerical form that deep neural networks can understand.\n",
    "\n",
    "#### More on it in next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
